\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\usepackage{textcomp}
\usepackage[colorlinks=true,urlcolor=blue]{hyperref}  % TODO: see page 94 of latex book
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{relsize}

\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}



\title{CSCI 181 / E-181 Spring 2014 \\ 
{\large 2nd midterm review}
}
\author{
  David Wihl\\
  \texttt{davidwihl@gmail.com}
}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\section{Support Vector Machines}

\subsection{Background}
Characteristics of SVMs:
\begin{itemize}
	\item \emph{stock} -- SVMs are "off the shelf" and ready to use. No special modification is necessary.
	\item \emph{linearly separable} -- assumes that linear separation is possible. Used natively as a binary classifier.
	\item \emph{convex optimization}. SVM originated as a backlash against neural nets due to nets' non-convexity. In Neural Nets, results were often non-reproducible as different researchers found different results due to different initializations.
	\item \emph{global optimum} -- SVMs will find the global optimum.
\end{itemize}

SVMs are based on three "big ideas":
\begin{itemize}
	\item \emph{margin} Maximizes distance between the closest points
	\item \emph{duality} Take a hard problem and transform it into an easier problem to solve.
	\item \emph{kernel trick} Map input vectors to higher dimensional, more expressive features.
\end{itemize}

\subsection{Definitions}

\begin{description}
	\item[Data:] $\{x_n,t_n\}_{n=1}^N, t_n \in \{-1, +1\}$. $t_n$ is the target or the expected result of the classification.
	\item[J Basis functions:] $\phi_j(x)\rightarrow\Re$, therefore
	\begin{description}
		\item[Vector function:] $\Phi X \rightarrow \Re^J$ produces a column vector.
	\end{description}
	\item[Objective function:]
$f(\textbf{x},\textbf{w},b) = \textbf{w}^\intercal \mathbf{\phi}(\textbf{x})  + b$
where b is the bias.
\end{description}

The sign of $f(\cdot)$ will determine classification $(-1,+1)$

So the actual classifier will be:
\[
y(\textbf{x},\textbf{w},b) =
	\begin{cases}
	  	+1, &\text{if  }\textbf{w}^\intercal \mathbf{\phi}(\textbf{x}) + b > 0 \\
		-1, &\text{otherwise}
	\end{cases}
\]

Unlike Logistic Regression (which uses $\{0, 1\}$), it is preferable to use $\{-1, +1\}$ as the classification result. If $t_n * y$ is positive, then the produced classification is correct (positive $\times$ positive is positive, negative $\times$ negative is also positive).

\emph{Decision Boundary} is the hyperplane where $\textbf{w}^\intercal \phi(\textbf{x}) +b = 0$ . We want to find the Decision Boundary that creates the most separation between the two different classes by maximizing the distance between the two closest points. The distance between the Decision Boundary and the closest point is called the \emph{margin}. The points closest to the Decision Boundary are called the \emph{support vectors}.

\subsection {Max Marginalization}

The margin is determined by the orthogonal distance from the closest point to the Decision Boundary: 
\begin{equation}
\frac{|\textbf{w}^\intercal \textbf{x} + b|}{||\textbf{w}||}
\end{equation}


Maximizing the margin can be written as:
\begin{equation}
\argmax_{w,b} \left\{\min_n(t_n\cdot(\mathbf{w}^\intercal\mathbf{x}+b))\cdot\frac{1}{||w||} \right\}
\end{equation}

Maximizing the margin helps ensure that points which are close to margin will not be pushed over the boundary by noise.

$\mathbf{w}$ is orthogonal to vectors in the Decision Boundary. Here's how: pick two points on the Decision Boundary $\phi(x_1) \text{ and } \phi(x_2)$. So
\begin{align}
\mathbf{w}&^\intercal\left(\phi(x_2) - \phi(x_1)\right) = 0 \text{ for orthogonal dot product}\nonumber \\
\mathbf{w}&^\intercal\phi(x_2) - \mathbf{w}^\intercal\phi(x_1) = 0 \nonumber \\
\text{Note: } \mathbf{w}&^\intercal\phi(x_n) = (-b) \text{, so} \nonumber \\
=&(-b) - (-b) \nonumber \\
=& 0 \nonumber
\end{align}

Since $\mathbf{w}$ is orthogonal, we want to maximize it. It is not unit length, but could be, by scaling with a factor of $r$.

See \href{http://cs229.stanford.edu/notes/cs229-notes3.pdf}{Stanford CS229 SVM Notes} re: Functional vs. Geometric Margins

The support vector is defined as $r\frac{\mathbf{w}}{||\mathbf{w}||_2}$, where $r$ is multiplied by the unit vector orthogonal to the Decision Boundary hyperplane. 

Define the point where the vector meets the plane as $\phi_\perp (\mathbf{x})$, so
\begin{equation}
\phi(\mathbf{x}) = \phi_\perp(\mathbf{x}) + r\frac{\mathbf{w}}{||\mathbf{w}||_2}
\end{equation}

Solving for $r$, multiple both sides by $\mathbf{w}^\intercal$.

(Recall: $\mathbf{w}^\intercal\mathbf{w} = ||\mathbf{w}||^2$)

\begin{align}
\mathbf{w}^\intercal\phi(\mathbf{x}) = &\mathbf{w}^\intercal  \phi_\perp(\mathbf{x})  +	 r\frac{\mathbf{w}^\intercal\mathbf{w}}{||\mathbf{w}||} \\
			 = & (-b) + r||\mathbf{w}||
\end{align}
Therefore, the margin for a point $\mathbf{x}$.
\begin{align}
r = &\frac{\phi(\mathbf{x})^\intercal\mathbf{w}+b}{||w||} \\
  = & \frac{f(\mathbf{x},\mathbf{w},b)}{||w||}
\end{align}
This makes it easy to calculate how far away a point is from the Decision Boundary. $r$ is strictly not a length because it could be negative. However, we only care about the actual distance to the boundary.

Margin for a datum $n$:
\begin{equation}
margin = t_n\frac{\phi(\mathbf{x})^\intercal\mathbf{w}+b}{||\mathbf{w}||}
\end{equation}

This is getting close to a loss function as we can now figure out the worst of these. The Margin for all the training data will be the point closest to the Decision Boundary:
\begin{equation}
min_n\left\{ t_n\frac{\phi(\mathbf{x})^\intercal\mathbf{w}+b}{||\mathbf{w}||} \right\}
\end{equation}

As mentioned at the beginning of this section, the Objective Function is 
\begin{equation}
\mathbf{w}^*,b^*=
\argmax_{w,b} \left\{\min_n(t_n\cdot(\phi(\mathbf{x})^\intercal\mathbf{w}+b))\cdot\frac{1}{||w||} \right\}
\end{equation}

but now we can simplify some things. $\mathbf{w}$ are $b$ are scale free (if we multiply by some $\beta$, the max and min will still be the same.)

Let's define a set of linear constraints such that the margin is always $\ge 1$ to make this easier to solve.
\begin{align}
\mathbf{w}^*,b^*= \argmax_{\mathbf{w},b}\frac{1}{||w||}
\end{align}
subject to 
\begin{align}
t_n\cdot(\phi(x_n)^\intercal\mathbf{w}+b) \ge 1 \:\forall\: n
\end{align}
This can be made even easier. Finding the max of $\frac{1}{||w||}$ is like finding the min of $||w||^2$, so
\begin{align}
\mathbf{w}^*,b^*=& \argmin_{\mathbf{w},b}||w||^2 \\
\text{s.t.} \:& t_n(\phi(x_n)^\intercal\mathbf{w} + b) \ge 1
\end{align}
so this reduces to just a quadratic program (QP) with linear constraints that could be solved by any number of commercial packages and produces a global minimum.

\subsection{Slack Variables}
If the data is not strictly linearly separable, it can mitigated by slack variables.

$\xi_n \leftarrow$ one for each datum. 
\begin{description}
 \item[$\xi_n = 0$] then the datum is correctly classified and outside the margin.
 \item[$0 < \xi_n <= 1$] the datum is correctly classified and within the margin
 \item[$\xi_n > 1$] the datum is misclassified
\end{description}

We will now add $\xi$ as a constraint to minimize.
\begin{equation}
t_n\cdot(\phi(x_n)^\intercal\mathbf{w}+b) \ge 1 - \xi_n
\end{equation}
New objective function:
\begin{align}
\mathbf{w}^*,b^*,\xi^*=& \argmin_{\mathbf{w},b,\mathbf{\xi}}\left\{||w||^2+ c \sum_{n=1}^{N}\xi_n\right\}\\
\text{s.t.} \:& t_n(\phi(x_n)^\intercal\mathbf{w} + b) \ge 1 -\xi_n\\
& \xi \ge 0\\
\forall \:n
\end{align}
where $c>0$ is the regularization parameter. A small $C$ means that you don't care much about errors. The sum of $\xi$ is the upper bound on how many can be wrong. If $c = 0$, it becomes the original function.
Typically,
\begin{equation}
c=\frac{1}{\nu N} \text{, where } 0 < \nu \le 1
\end{equation}
where $\nu$ is the tolerance for percentage willing to get wrong.

\subsection {Duality}

\subsection {Kernel Tricks}
Mercer function, infinite dimensions (justification for duality)

Slack variables to break the linear separability.

\subsection{Sources}

\begin{enumerate}
	\item Lecture 14, March 24, 2014
	\item Lecture 15
	\item Bishop 6.0-6.2 
	\item Bishop 7.0-7.1
	\item Course notes - maxmargin
	\item Section 7 review
	\item Section 8 review
	\item Stanford CS229 SVM notes
	\item Machine Learning in Action, Chapter 6
\end{enumerate}

\section{Markov Decision Processes}
Lecture 16

Course notes - MDP

Section 9

\subsection{Partially Observable MDP}
Course notes - POMDP

Section 10

\subsection{Hidden Markov Models}
Bishop 13.0-13.2

\subsection{Mixture Models}
Bishop 9.0-9.2

\section{Reinforcement Learning}
Course notes - RL

Section 9

\subsection{Value and Policy Iteration}
Lecture 17

Course notes - policyiter

\section{Expectation Maximization}

Bishop 9.3

Section 11


\end{document}  
